{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### T2 Data Analysis  \n",
    "\n",
    "        Sean Keenan, PhD Physics  \n",
    "        Quantum Memories Group, Heriot-Watt University, Edinburgh  \n",
    "        2024  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add the parent directory to the system path\n",
    "sys.path.insert(1, r\"C:\\Users\\keena\\Documents\\University\\python_scripts\")\n",
    "\n",
    "import Function_files.data_functions as dat\n",
    "from Function_files.fitting_functions import find_trigger, fit_exp_decay\n",
    "from Function_files.math_functions import average_arrays\n",
    "from Function_files.plotting_class import Plotter\n",
    "from Function_files.addresses import Init_Directories\n",
    "\n",
    "from Lifetime.T2 import T2_config as config_file\n",
    "\n",
    "dirs = Init_Directories()\n",
    "plt = Plotter()\n",
    "\n",
    "# set plot save location and format\n",
    "plt.format = 'svg'\n",
    "plt.dir = dirs.code\n",
    "plt.folder = \"Downloads/0403_T2/T2_0\"\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Import Data  \n",
    "        \n",
    "        Load data sets & extract time and voltage data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import config_file\n",
    "config = config_file.config_params\n",
    "# path to folders containing T1 data\n",
    "path = os.path.join(config['root'], config['file'])\n",
    "# extensions to look for in the folders\n",
    "exts = config['extensions']\n",
    "# indexes for data\n",
    "di = config['data_indexes']\n",
    "ti = config['trim_indexes']\n",
    "# make labels from data indexes\n",
    "labels = [key for key in di.keys() if key != 'time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate folder and file lists\n",
    "folder_list, file_list = dat.dir_interrogate(path, extensions=exts)\n",
    "# create dictionary for indexing folders and files\n",
    "folder_index = dat.make_index_dict(folder_list)\n",
    "file_index = [dat.make_index_dict(file_sub_list) for file_sub_list in file_list]\n",
    "# lists of the data paths and metadata (text) paths\n",
    "data_path_list = dat.search_paths(folder_list, [file_list], [exts[0]])\n",
    "metadata_path_list = dat.search_paths(folder_list, file_list, [exts[1]])\n",
    "# extract the relevant data from the files\n",
    "excel_sets = [dat.open_csv(os.path.join(path, data_path), header=0) for data_path in data_path_list]\n",
    "metadata = [dat.open_text(os.path.join(path, data_path)) for data_path in metadata_path_list]\n",
    "# populate dictionary for extracting from the metadata\n",
    "#test = dat.create_dict(os.path.join(path, metadata_path_list[0][0]), delimiter='=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot channel data to check assignment (times are in us)\n",
    "set = 0         # data set to use\n",
    "file = 0         # file in the data set\n",
    "plt.scale_x = 1E6\n",
    "plt.scale_y = 1\n",
    "fig, ax = plt.plot_scope(excel_sets[set][:,di['time']], [excel_sets[set][:,di['trig']], excel_sets[set][:,di['pulse']], excel_sets[set][:,di['echo']]], titles=labels, multi=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Fine Tune Trigger Point\n",
    "\n",
    "        Check the trigger index and adjust if neccesary\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find inex of the trigger\n",
    "trig_indexes = [[find_trigger(trig_data[:,di['trig']], modifier=.9) for trig_data in excel_data] for excel_data in [excel_sets]]\n",
    "ti['trig'] = trig_indexes[0][0]\n",
    "# calculate the time step\n",
    "dt = (excel_sets[0][:,di['time']][1] - excel_sets[0][:,di['time']][0])*1E6\n",
    "\n",
    "# create offset beased on time step\n",
    "ti['ramp'] = round(1.2/dt) + trig_indexes[0][0]\n",
    "ti['off'] = round(0)\n",
    "#ti['ref_off'] = round(0.6/dt) \n",
    "\n",
    "# plot transmitted and reference data to check the trigger index\n",
    "plt.scale_x = 1E6\n",
    "plt.scale_y = 1\n",
    "fig, ax = plt.plot_T2_trigger(excel_sets[0][:,di['time']], excel_sets[0][:,di['echo']], ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as mp\n",
    "from scipy.signal import savgol_filter as svg\n",
    "\n",
    "smoothed = fil.smooth_data(excel_sets[0][:,di['echo']][ti['trig']:ti['off']], 10000, 'gaussian')\n",
    "mp.plot(smoothed)\n",
    "mp.plot(np.diff(smoothed)*1E4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Process Data  \n",
    "\n",
    "        Trim the data sets and find initial starting parameters for fitting\n",
    "        Fit to the data and take average fit values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find start and stop indexes for the data (saves trying to fit to unnecesary data)\n",
    "start_set = [[value + ti['off'] for value in trig_index] for trig_index in trig_indexes]\n",
    "\n",
    "# create new arrays of cut data using start and stop indexes found\n",
    "time_sets = [[data[:,di['time']][start:ti['ramp']] for data, start in zip(data_list, start_list)] for data_list, start_list in zip([excel_sets], start_set)]\n",
    "trig_sets = [[data[:,di['trig']][start:ti['ramp']] for data, start in zip(data_list, start_list)] for data_list, start_list in zip([excel_sets], start_set)]\n",
    "trans_sets = [[data[:,di['echo']][start:ti['ramp']] for data, start in zip(data_list, start_list)] for data_list, start_list in zip([excel_sets], start_set)]\n",
    "\n",
    "# found initial start params for the fitting functions (minimum and maximum)\n",
    "list_of_mins = [[min(trans) for trans in trans_lists] for trans_lists in trans_sets]\n",
    "list_of_maxs = [[max(trans) for trans in trans_lists] for trans_lists in trans_sets]\n",
    "\n",
    "# zip the fit data for the reference signal\n",
    "data_zip = zip(time_sets, trans_sets,list_of_maxs,list_of_mins)\n",
    "\n",
    "# fit to the transmitted data and average the fit\n",
    "data_fit_sets = [[fit.fit_gauss(time, trans, params=(max_value, min_value)) for time, trans, max_value, min_value in zip(time_set, trans_set, max_set, min_set)] for time_set, trans_set, max_set, min_set in data_zip]\n",
    "data_fit_avg = [mat.average_arrays(data_list) for data_list in data_fit_sets]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lifetime_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
