{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### T1 Data Analysis  \n",
    "\n",
    "        Sean Keenan, PhD Physics  \n",
    "        Quantum Memories Group, Heriot-Watt University, Edinburgh  \n",
    "        2024  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add the parent directory to the system path\n",
    "sys.path.insert(1, r\"C:\\Users\\keena\\Documents\\University\\python_scripts\")\n",
    "\n",
    "from Function_files.addresses import Init_Directories\n",
    "import Function_files.data_functions as dat\n",
    "from Function_files.fitting_functions import find_trigger, fit_exp_decay\n",
    "from Function_files.math_functions import average_arrays\n",
    "from Function_files.plotting_class import Plotter\n",
    "\n",
    "plt = Plotter()\n",
    "dirs = Init_Directories()\n",
    "\n",
    "from scipy.integrate import simpson\n",
    "\n",
    "dirs.current = dirs.join(dirs.code, \"Lifetime\\T1\")\n",
    "json = dirs.join(dirs.current, \"configs\", \"0925.json\")\n",
    "info = dat.read_json(json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Import Data  \n",
    "        \n",
    "        Load data sets & extract time and voltage data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to folders containing T1 data\n",
    "path = dirs.join(info['file_loc'], \"traces\")\n",
    "# indexes for data\n",
    "di = info['data_indexes']\n",
    "ti = info['trim_indexes']\n",
    "# make labels from data indexes\n",
    "labels = [key for key in di.keys() if key != 'time']\n",
    "# populate folder and file lists\n",
    "folder_list, file_list = dat.dir_interrogate(path, extensions=info['extensions'])\n",
    "# create dictionary for indexing folders and files\n",
    "folder_index = dat.make_index_dict(folder_list)\n",
    "file_index = [dat.make_index_dict(file_sub_list) for file_sub_list in file_list]\n",
    "# lists of the data paths and metadata (text) paths\n",
    "data_path_list = dat.search_paths(folder_list, file_list, [info['extensions'][0]])\n",
    "metadata_path_list = dat.search_paths(folder_list, file_list, [info['extensions'][1]])\n",
    "# extract the relevant data from the files\n",
    "excel_sets = [[dat.open_csv(dirs.join(path, data_path), header=0) for data_path in data_paths] for data_paths in data_path_list]\n",
    "if '.txt' in info['extensions']:\n",
    "        metadata = [dat.open_text(dirs.join(path, data_path)) for data_paths in metadata_path_list for data_path in data_paths]\n",
    "        fluor_duration = [[float(dat.find_numbers(row)[0]) for row in text_file if dat.check_str([\"durationFluor\"], row.split())] for text_file in metadata]\n",
    "elif '.json' in info['extensions']:\n",
    "        metadata = [dat.read_json(dirs.join(path, data_path)) for data_paths in metadata_path_list for data_path in data_paths]\n",
    "        fluor_duration = [[data['pi_half_params']['duration'] for data in meta_files] for meta_files in [metadata]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Fine Tune Trigger Point\n",
    "\n",
    "        Check the trigger index and adjust if neccesary\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot channel data to check assignment (times are in us)\n",
    "set = 0         # data set to use\n",
    "file = 0         # file in the data set\n",
    "plt.scale_x = 1E3\n",
    "plt.scale_y = 1E3\n",
    "fig, ax = plt.plot_scope(excel_sets[set][file][:,di['time']], [excel_sets[set][file][:,di['trig']], excel_sets[set][file][:,di['ref']], excel_sets[set][file][:,di['trans']]], titles=labels, multi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find index of the trigger\n",
    "set = 0          # data set to use\n",
    "file = 0        # file in the data set\n",
    "trig_indexes = [[find_trigger(trig_data[:,di['trig']], modifier=.9, edge='fall') for trig_data in excel_data] for excel_data in excel_sets]\n",
    "ti['trig'] = trig_indexes[set][file]\n",
    "# calculate the time step\n",
    "dt = (excel_sets[set][file][:,di['time']][1] - excel_sets[0][0][:,di['time']][0])*1E6\n",
    "# create offset based on time step\n",
    "fix_indexes = True\n",
    "if fix_indexes:\n",
    "    ti['ramp'] = round(1/dt) + trig_indexes[set][file]         # extend plotted data\n",
    "    ti['off'] = round(0.5/dt)                                     # offset to add to trigger  \n",
    "    ti['ref_off'] = round(0.5/dt)                                 # reference offset  \n",
    "    #dat.write_file(json, info, 'json')\n",
    "\n",
    "# plot transmitted and reference data to check the trigger index\n",
    "plt.scale_x = 1E6\n",
    "plt.scale_y = 1E3\n",
    "fig, ax = plt.plot_T1_trigger(excel_sets[set][file][:,di['time']], [excel_sets[set][file][:,di['ref']], excel_sets[set][file][:,di['trans']]], ti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Process Data  \n",
    "\n",
    "        Trim the data sets and find initial starting parameters for fitting\n",
    "        Fit to the data and take average fit values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find start and stop indexes for the data (saves trying to fit to unnecesary data)\n",
    "ref_stop_set = [[round(info['guess_ref_T1']*4/(time[:,di['time']][1] - time[:,di['time']][0])) for time in time_lists] for time_lists in excel_sets]\n",
    "stop_set = [[round(info['guess_T1']*1.5 /(time[:,di['time']][1] - time[:,di['time']][0])) for time in time_lists] for time_lists in excel_sets]\n",
    "start_set = [[value + ti['off'] for value in trig_index] for trig_index in trig_indexes]\n",
    "ref_start_set = [[value + ti['ref_off'] for value in trig_index] for trig_index in trig_indexes]\n",
    "# create new arrays of cut data using start and stop indexes found\n",
    "time_sets = [[data[:,di['time']][start:start+stop] for data, start, stop in zip(data_list, start_list, stop_lists)] for data_list, start_list, stop_lists in zip(excel_sets, start_set, stop_set)]\n",
    "ref_time_sets = [[data[:,di['time']][start:start+stop] for data, start, stop in zip(data_list, start_list, stop_lists)] for data_list, start_list, stop_lists in zip(excel_sets, ref_start_set, ref_stop_set)]\n",
    "trig_sets = [[data[:,di['trig']][start:start+stop] for data, start, stop in zip(data_list, start_list, stop_lists)] for data_list, start_list, stop_lists in zip(excel_sets, start_set, stop_set)]\n",
    "trans_sets = [[data[:,di['trans']][start:start+stop] for data, start, stop in zip(data_list, start_list, stop_lists)] for data_list, start_list, stop_lists in zip(excel_sets, start_set, stop_set)]\n",
    "ref_sets = [[data[:,di['ref']][start:start+stop] for data, start, stop in zip(data_list, start_list, stop_lists)] for data_list, start_list, stop_lists in zip(excel_sets, ref_start_set, ref_stop_set)]\n",
    "# found initial start params for the fitting functions (minimum and maximum)\n",
    "list_of_mins = [[min(trans) for trans in trans_lists] for trans_lists in trans_sets]\n",
    "list_of_maxs = [[max(trans) for trans in trans_lists] for trans_lists in trans_sets]\n",
    "ref_min_list = [[min(refs) for refs in ref_lists] for ref_lists in ref_sets]\n",
    "ref_max_list = [[max(refs) for refs in ref_lists] for ref_lists in ref_sets]\n",
    "# zip the fit data for the reference signal\n",
    "ref_zip = zip(ref_time_sets, ref_sets, ref_max_list, ref_min_list)\n",
    "data_zip = zip(time_sets, trans_sets, list_of_maxs, list_of_mins)\n",
    "# fit to the reference data\n",
    "ref_fit_sets = [[fit_exp_decay(time, ref, params=(max_value, info['guess_ref_T1'], min_value)) for time, ref, max_value, min_value in zip(time_set, ref_set, max_set, min_set)] for time_set, ref_set, max_set, min_set in ref_zip]\n",
    "# fit to the transmitted data\n",
    "data_fit_sets = [[fit_exp_decay(time, trans, params=(max_value, info['guess_T1'], min_value)) for time, trans, max_value, min_value in zip(time_set, trans_set, max_set, min_set)] for time_set, trans_set, max_set, min_set in data_zip]\n",
    "# calculate area of the fluorescence\n",
    "data_area_sets = [[simpson(y=trans, x=time) for trans, time in zip(trans_set, time_set)] for trans_set, time_set in zip(trans_sets, time_sets)]\n",
    "# calculate averages\n",
    "#ref_fit_avg = [average_arrays(ref_list) for ref_list in ref_fit_sets]\n",
    "data_fit_avg = [average_arrays(data_list) for data_list in data_fit_sets]\n",
    "data_area_avg = [average_arrays(data_list) for data_list in data_area_sets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as mp\n",
    "from Function_files.fitting_functions import exp_decay\n",
    "\n",
    "def plot_T1_fit(time, data, fit_params):\n",
    "        '''\n",
    "        Plot T1 fitted data on top of experimental data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        time: array\n",
    "            Time data for corresponding fit_params\n",
    "        data: array\n",
    "            Y data for the corresponding fit_params\n",
    "        fit_params: list / tuple\n",
    "            Fit parameters to use in exp_decay function \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        fig, ax: \n",
    "            Figure and axes handles for the plot\n",
    "\n",
    "        '''\n",
    "        if type(fit_params) == tuple:\n",
    "            fit = fit_params[0]\n",
    "        else:\n",
    "            fit = fit_params\n",
    "\n",
    "        scale_x = 1E6\n",
    "        scale_y = 1E3\n",
    "\n",
    "        # make label for plots\n",
    "        scale_time = time * scale_x\n",
    "\n",
    "        fig_1, ax_1 = mp.subplots()\n",
    "        \n",
    "        ax_1.plot(scale_time, (data - fit[-1]) * scale_y, color='C0', alpha=0.8, label='Exp. Data')\n",
    "        ax_1.plot(scale_time, (exp_decay((time), *fit) - fit[-1]) * scale_y, color='C1', linestyle='--', alpha=1, label='Fit')\n",
    "        ax_1.set_yscale('linear')\n",
    "        ax_1.set(ylabel=f'Voltage (mV)')\n",
    "        ax_1.legend()\n",
    "        ax_1.set(xlabel=f'Time ($\\\\mu$s)')\n",
    "\n",
    "        fig_2, ax_2 = mp.subplots()\n",
    "\n",
    "        ax_2.plot(scale_time, (data - fit[-1]) * scale_y, color='C0', alpha=0.8, label='Exp. Data')\n",
    "        ax_2.plot(scale_time, (exp_decay((time), *fit) - fit[-1]) * scale_y, color='C1', linestyle='--', alpha=1, label='Fit')\n",
    "        ax_2.set_yscale('log')\n",
    "        ax_2.set(ylabel=f'$\\log_1$$_0$ Voltage (mV)')\n",
    "        ax_2.legend()\n",
    "        ax_2.set(xlabel=f'Time ($\\\\mu$s)')\n",
    "\n",
    "        return fig_2, ax_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Function_files.addresses import Init_Directories\n",
    "dirs = Init_Directories()\n",
    "plt.format = 'svg'\n",
    "plt.dir = dirs.code\n",
    "plt.folder = \"Lifetime/T1/fit_data/PrYSO_05pc/\"\n",
    "plt.fname = 'log T1'\n",
    "#plt.save_fig(figure=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_T1_fit(time_sets[0][0], trans_sets[0][0], data_fit_sets[0][0])\n",
    "print(data_fit_sets[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['I0', 'T1', 'y0']\n",
    "err_keys = ['dI0', 'dT1', 'dy0']\n",
    "fit_data = {}\n",
    "\n",
    "for duration, data_fit, data_area in zip(fluor_duration, data_fit_avg, data_area_avg):\n",
    "    duration_dict = {}\n",
    "    for key, value in zip(keys, data_fit[0][0].flatten().tolist()):\n",
    "        duration_dict[key] = value\n",
    "    for key, value in zip(err_keys, data_fit[1][0].flatten().tolist()):\n",
    "        duration_dict[key] = value\n",
    "    # Add area to the dict\n",
    "    duration_dict['A'] = data_area[0]\n",
    "    duration_dict['dA'] = data_area[1]\n",
    "    # After populating duration_dict with all key-value pairs, assign it to fit_data\n",
    "    fit_data[duration[0]] = duration_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to file\n",
    "dat.write_json(dirs.join(dirs.current, fit_data), fit_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lifetime_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
